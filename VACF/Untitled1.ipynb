{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f2e65bc-dc67-499f-be0b-717e358826ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b0b2951-2ccb-4fd3-8e81-2e8d14c86f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = 'Crystalline'\n",
    "mcg = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4abbd001-77f7-4829-95d6-95ff1e45b96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'/leonardo_scratch/large/userexternal/mhaeupl0/InitialTrajectories/{structure}/cv_{mcg}/N_out_1_N_10e5/trajectory.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01fce474-0971-4ac9-aa2f-1761b65ced2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying coordinates:   4%|▌            | 4000/100001 [00:45<18:16, 87.58frame/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n_frames, chunk_size):\n\u001b[1;32m     53\u001b[0m     chunk_end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(i \u001b[38;5;241m+\u001b[39m chunk_size, n_frames)\n\u001b[0;32m---> 54\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mdset_in\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_frame\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mchunk_end\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     55\u001b[0m     dset_out[i:chunk_end] \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m     56\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))  \u001b[38;5;66;03m# Update progress bar\u001b[39;00m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/clathrate_env/lib/python3.8/site-packages/h5py/_hl/dataset.py:758\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying coordinates:   4%|▌            | 4000/100001 [00:59<18:16, 87.58frame/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "input_file = file_path\n",
    "output_file = \"output_short.hdf5\"\n",
    "start_frame = 0\n",
    "end_frame = 100000  # inclusive\n",
    "chunk_size = 1000   # Adjust based on memory (1000-10000)\n",
    "position_path = \"coordinates\"  # Path to position dataset\n",
    "velocity_path = \"velocities\"   # Path to velocity dataset\n",
    "\n",
    "with h5py.File(input_file, \"r\") as f_in, h5py.File(output_file, \"w\") as f_out:\n",
    "    # Copy root attributes\n",
    "    for key, value in f_in.attrs.items():\n",
    "        f_out.attrs[key] = value\n",
    "\n",
    "    # Copy non-dataset objects (groups, metadata)\n",
    "    def copy_items(name, obj):\n",
    "        if isinstance(obj, h5py.Group):\n",
    "            # Create group and copy attributes\n",
    "            group = f_out.create_group(name)\n",
    "            for key, value in obj.attrs.items():\n",
    "                group.attrs[key] = value\n",
    "        elif isinstance(obj, h5py.Dataset) and name not in [position_path, velocity_path]:\n",
    "            # Copy non-trajectory datasets\n",
    "            f_in.copy(name, f_out, name=name)\n",
    "\n",
    "    f_in.visititems(copy_items)\n",
    "\n",
    "    # Process trajectory datasets\n",
    "    for path in [position_path, velocity_path]:\n",
    "        dset_in = f_in[path]\n",
    "        n_frames = end_frame - start_frame + 1\n",
    "        total_chunks = int(np.ceil(n_frames / chunk_size))\n",
    "        \n",
    "        # Create output dataset with same properties\n",
    "        dset_out = f_out.create_dataset(\n",
    "            path,\n",
    "            shape=(n_frames,) + dset_in.shape[1:],\n",
    "            dtype=dset_in.dtype,\n",
    "            chunks=dset_in.chunks,\n",
    "            compression=dset_in.compression,\n",
    "            compression_opts=dset_in.compression_opts\n",
    "        )\n",
    "        \n",
    "        # Initialize progress bar\n",
    "        pbar = tqdm(\n",
    "            total=n_frames,\n",
    "            desc=f\"Copying {path.split('/')[-1]}\",\n",
    "            unit=\"frame\",\n",
    "            dynamic_ncols=True\n",
    "        )\n",
    "        \n",
    "        # Copy data in chunks\n",
    "        for i in range(0, n_frames, chunk_size):\n",
    "            chunk_end = min(i + chunk_size, n_frames)\n",
    "            chunk = dset_in[start_frame + i : start_frame + chunk_end]\n",
    "            dset_out[i:chunk_end] = chunk\n",
    "            pbar.update(len(chunk))  # Update progress bar\n",
    "            \n",
    "        pbar.close()\n",
    "        \n",
    "        # Copy dataset attributes\n",
    "        for key, value in dset_in.attrs.items():\n",
    "            dset_out.attrs[key] = value\n",
    "\n",
    "print(f\"\\nSaved frames {start_frame}-{end_frame} to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebcff1e-048f-4cae-8658-9f81f4ce5378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
